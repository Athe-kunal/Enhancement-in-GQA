{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer,T5Config\n",
    "from transformers.models.t5.modeling_t5 import T5Attention, T5Config, T5Block\n",
    "from copy import deepcopy\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.models.t5.modeling_t5 import T5Attention, T5LayerSelfAttention, T5LayerCrossAttention\n",
    "\n",
    "t5: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_tf_attention_dict(module,kv_heads:int=4):\n",
    "    transfer_to_gqa: List[str] = [\"decoder\",\"EncDecAttention\"]\n",
    "    tf_attention_dict = defaultdict(list)\n",
    "    def convert_t5_to_gqa(module, kv_heads: int,similarity_flag:bool=False,inplace: bool = False,curr_name:str=''):\n",
    "        \"\"\"Get the list of attention modules based on the flag about encoder, decoder or cross-attention\n",
    "\n",
    "        Args:\n",
    "            module: Transformer module/unit\n",
    "            kv_heads (int): Number of key-value heads\n",
    "            similarity_flag (bool, optional): Similarity GQA flag. Defaults to False.\n",
    "            inplace (bool, optional): inplace replace the model with GQA. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        if isinstance(module, T5Attention) and similarity_flag:\n",
    "            print(curr_name)\n",
    "            tf_attention_dict[curr_name].append(module)\n",
    "\n",
    "        out = module if inplace else deepcopy(module)\n",
    "        for name, child in out.named_children():\n",
    "            if name in transfer_to_gqa:\n",
    "                curr_name = name\n",
    "                similarity_flag = True\n",
    "            out._modules[name] = convert_t5_to_gqa(child, kv_heads=kv_heads,similarity_flag=similarity_flag, inplace=True,curr_name=curr_name)\n",
    "        return out\n",
    "\n",
    "    convert_t5_to_gqa(module,kv_heads=kv_heads)\n",
    "    return tf_attention_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n"
     ]
    }
   ],
   "source": [
    "tf_attn_dict = get_tf_attention_dict(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['decoder', 'EncDecAttention'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_attn_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_attn_dict['EncDecAttention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Attention(\n",
       "  (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (relative_attention_bias): Embedding(32, 8)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_qkv = tf_attn_dict['decoder'][0]\n",
    "first_qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = first_qkv.q.weight.data.T\n",
    "k = first_qkv.k.weight.data.T\n",
    "v = first_qkv.v.weight.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([512, 512]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape,q.shape,k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "#define 8 weights one for each key head and 8 weights one for each value head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your original matrix is named 'input_matrix' with dimensions (512, 512)\n",
    "input_matrix = torch.rand((512, 512))\n",
    "\n",
    "# Define the weight scalars w1, w2, ..., w8\n",
    "w_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# Reshape the input matrix to (512, 8, 64) to represent the 8 heads\n",
    "input_matrix_reshaped = input_matrix.view(512, 8, 64)\n",
    "\n",
    "# Multiply each head with its corresponding weight scalar\n",
    "output_heads = torch.stack([input_matrix_reshaped[:, i, :] * w_values[i] for i in range(8)], dim=1)\n",
    "\n",
    "# Sum the weighted heads along the second dimension to combine them\n",
    "output_matrix = output_heads.sum(dim=1)\n",
    "\n",
    "# Verify the shape of the resulting matrix (512, 512)\n",
    "print(output_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 65])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones((512,512))\n",
    "print(w)\n",
    "w = w.view(512,8,64)\n",
    "#(8x1) and (512,8,64)\n",
    "mul_val = torch.tensor([[0.1],[0.2],[0.4],[0.3],[0.5],[0.6],[0.7],[0.8]])\n",
    "# print(mul_val.shape)\n",
    "# w_1 = torch.reshape(w,())\n",
    "final_val = torch.multiply(w,mul_val)\n",
    "fv = final_val.view(512,512)\n",
    "fv[:,:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        ...,\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "w = torch.ones((512, 512))\n",
    "print(w)\n",
    "\n",
    "w = w.view(512, 8, 64)\n",
    "# (8x1) and (512,8,64)\n",
    "mul_val = torch.tensor([[0.1], [0.2], [0.4], [0.3], [0.5], [0.6], [0.7], [0.8]])\n",
    "\n",
    "# Ensure mul_val has the same size as the second dimension of w\n",
    "mul_val = mul_val.view(1, 8, 1)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "final_val = torch.multiply(w, mul_val)\n",
    "\n",
    "# Reshape the result to the original shape (512, 512)\n",
    "fv = final_val.view(512, 512)\n",
    "\n",
    "print(fv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23397/3759601383.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  print(mul_val.T.shape)\n"
     ]
    }
   ],
   "source": [
    "print(mul_val.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_0_5 = torch.full((8, 1), 0.5)\n",
    "\n",
    "# Print the resulting tensor\n",
    "print(tensor_0_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn((8,1))\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,attn_module in tf_attn_dict['decoder']:\n",
    "    q = attn_module.q.weight.data.T\n",
    "    k = attn_module.k.weight.data.T\n",
    "    v = attn_module.v.weight.data.T\n",
    "\n",
    "    params = nn.ParameterDict({\n",
    "        f\"key_{idx}\": nn.Parameter(torch.full((num_heads,1),0.5)),\n",
    "        f\"value_{idx}\": nn.Parameter(torch.full((num_heads,1),0.5)),\n",
    "    })\n",
    "\n",
    "    k = k.view(512,num_heads,512//num_heads)\n",
    "    v = v.view(512,num_heads,512//num_heads)\n",
    "    k_mod = torch.multiply(k,params[f\"key_{idx}\"])\n",
    "    v_mod = torch.multiply(v,params[f\"value_{idx}\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b: batch_size\n",
    "# @n: seq_length\n",
    "# d: d_model\n",
    "# h:heads\n",
    "# k: same as d_model\n",
    "                #16,\n",
    "Q= tf .einsum(\"bnd,hdk->bhnk\" , X, P_q) \n",
    "K= tf .einsum(\"bmd,dk->bmk\" , M, P_k) \n",
    "V= tf .einsum(\"bmd,dv->bmv\" , M, P_v) \n",
    "logits = tf .einsum(\"bhnk,bmk->bhnm\", Q, K) \n",
    "weights= tf .softmax(logits +mask) \n",
    "O= tf .einsum(\"bhnm,bmv->bhnv\", weights , V)\n",
    "Y= tf .einsum(\"bhnv,hd->bnd\" , O, P_o) \n",
    "# return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello_there': 1, 'hello_jackass': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = {\"there\":1,\"jackass\":2}\n",
    "{\"hello_\"+k:v for k,v in c.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x\n",
    "torch.transpose(x, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHORT_SUM'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"SHORT_sum\".upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVE\n",
    "1. Take a GQA model, repeat interleave to expand it and then save it\n",
    "2. AFter that do again similarity based re-ordering and build the GQA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t5_SGQA import convert_t5_to_gqa\n",
    "from config import * \n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "t5: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\n",
    "        MODEL_NAME\n",
    "    )\n",
    "\n",
    "t5_gqa = convert_t5_to_gqa(t5,kv_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_gqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7012,  0.0801, -0.5273,  ..., -0.1401, -0.1582, -0.1323],\n",
       "        [ 0.7334,  0.3037, -0.4249,  ..., -0.4717, -0.4237,  0.3281],\n",
       "        [-0.2578, -0.4951, -0.1057,  ..., -0.1821,  0.0879,  0.3970],\n",
       "        ...,\n",
       "        [ 0.2568,  0.2129,  0.1433,  ...,  0.0942, -0.2583,  0.1055],\n",
       "        [-0.3193,  0.3030, -0.2520,  ...,  0.2054,  0.2778, -0.0842],\n",
       "        [ 0.1865, -0.1156,  0.1279,  ..., -0.0771,  0.1841,  0.2009]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = t5_gqa.decoder.block[0].layer[0].SelfAttention.k.weight.data\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 512])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped a = tensor([[[ 0.7012,  0.0801, -0.5273,  ..., -0.1401, -0.1582, -0.1323],\n",
      "         [ 0.7334,  0.3037, -0.4249,  ..., -0.4717, -0.4237,  0.3281],\n",
      "         [-0.2578, -0.4951, -0.1057,  ..., -0.1821,  0.0879,  0.3970],\n",
      "         ...,\n",
      "         [-1.2881, -0.3301, -0.0957,  ...,  0.5088, -0.1342,  0.1934],\n",
      "         [ 0.5796, -0.0742, -0.2427,  ...,  0.2109, -0.4469, -0.1626],\n",
      "         [-1.0469, -0.0698, -0.4209,  ...,  0.6631,  0.4346,  0.1270]],\n",
      "\n",
      "        [[ 0.4365, -0.4797,  0.1533,  ...,  0.3031,  1.4961, -0.2870],\n",
      "         [ 0.3274,  0.5293,  0.5322,  ..., -0.5205,  0.0137,  0.3191],\n",
      "         [-0.3218,  0.3838, -0.2642,  ..., -0.1895, -0.1450, -0.0293],\n",
      "         ...,\n",
      "         [ 0.3619, -0.0166,  0.1426,  ..., -0.2686, -0.2766,  0.3584],\n",
      "         [-0.1064,  0.2766,  0.2471,  ...,  0.1812, -0.2681,  0.7461],\n",
      "         [ 0.1543, -0.1621, -0.0557,  ...,  0.1201, -0.3467, -0.5791]],\n",
      "\n",
      "        [[ 0.1743,  0.4551, -0.1633,  ..., -0.4756,  0.1367,  0.1978],\n",
      "         [-0.2628,  0.4219,  0.5303,  ..., -0.3379,  0.1133, -0.1748],\n",
      "         [-0.1152,  0.0288,  0.3496,  ..., -0.2378, -0.2314, -0.1313],\n",
      "         ...,\n",
      "         [ 0.3558,  0.2410, -0.2373,  ...,  0.1212, -0.2783, -0.0088],\n",
      "         [ 0.0083,  0.0361, -0.3071,  ...,  0.8994,  0.1206,  0.1758],\n",
      "         [-0.0220, -0.4154, -0.3906,  ..., -0.3711,  0.2793,  0.8691]],\n",
      "\n",
      "        [[ 0.3032,  0.2109,  0.4854,  ...,  0.0420, -0.6367,  0.2632],\n",
      "         [ 0.4521,  0.0723, -0.4441,  ..., -0.3394,  0.5889, -0.2749],\n",
      "         [-0.1821, -0.0189,  0.0461,  ...,  0.2793, -0.1329, -0.0724],\n",
      "         ...,\n",
      "         [ 0.2568,  0.2129,  0.1433,  ...,  0.0942, -0.2583,  0.1055],\n",
      "         [-0.3193,  0.3030, -0.2520,  ...,  0.2054,  0.2778, -0.0842],\n",
      "         [ 0.1865, -0.1156,  0.1279,  ..., -0.0771,  0.1841,  0.2009]]])\n",
      "Shape = torch.Size([4, 64, 512])\n",
      "Expanded a =  tensor([[ 0.7012,  0.0801, -0.5273,  ..., -0.1401, -0.1582, -0.1323],\n",
      "        [ 0.7334,  0.3037, -0.4249,  ..., -0.4717, -0.4237,  0.3281],\n",
      "        [-0.2578, -0.4951, -0.1057,  ..., -0.1821,  0.0879,  0.3970],\n",
      "        ...,\n",
      "        [ 0.2568,  0.2129,  0.1433,  ...,  0.0942, -0.2583,  0.1055],\n",
      "        [-0.3193,  0.3030, -0.2520,  ...,  0.2054,  0.2778, -0.0842],\n",
      "        [ 0.1865, -0.1156,  0.1279,  ..., -0.0771,  0.1841,  0.2009]])\n",
      "Shape:  torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#               (d_model,kv_heads,d_model//n_heads)\n",
    "#(512,256) --> (512,4,64) --> repeat interleave along dimension one --> (512, 8, 64)\n",
    "\n",
    "d_model = 512 #512\n",
    "n_heads = 8 #8\n",
    "key_value_dim = d_model//n_heads #64\n",
    "kv_heads = 4 #4\n",
    "\n",
    "# a = torch.ones((256,512))\n",
    "\n",
    "\n",
    "# a[0,:] = 0.1\n",
    "# a[1,:] = 0.2\n",
    "# a[2,:] = 0.3\n",
    "# a[3,:] = 0.4\n",
    "\n",
    "a = k.view(kv_heads,key_value_dim,d_model)\n",
    "print(f\"Reshaped a = {a}\")\n",
    "print(f\"Shape = {a.shape}\")\n",
    "c = torch.repeat_interleave(a,2,dim=0).view(d_model,-1)\n",
    "\n",
    "print(\"Expanded a = \",c)\n",
    "print(\"Shape: \",c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7012,  0.0801, -0.5273,  ..., -0.1401, -0.1582, -0.1323],\n",
       "        [ 0.7334,  0.3037, -0.4249,  ..., -0.4717, -0.4237,  0.3281],\n",
       "        [-0.2578, -0.4951, -0.1057,  ..., -0.1821,  0.0879,  0.3970],\n",
       "        ...,\n",
       "        [-1.2881, -0.3301, -0.0957,  ...,  0.5088, -0.1342,  0.1934],\n",
       "        [ 0.5796, -0.0742, -0.2427,  ...,  0.2109, -0.4469, -0.1626],\n",
       "        [-1.0469, -0.0698, -0.4209,  ...,  0.6631,  0.4346,  0.1270]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:64,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7012,  0.0801, -0.5273,  ..., -0.1401, -0.1582, -0.1323],\n",
       "        [ 0.7334,  0.3037, -0.4249,  ..., -0.4717, -0.4237,  0.3281],\n",
       "        [-0.2578, -0.4951, -0.1057,  ..., -0.1821,  0.0879,  0.3970],\n",
       "        ...,\n",
       "        [-1.2881, -0.3301, -0.0957,  ...,  0.5088, -0.1342,  0.1934],\n",
       "        [ 0.5796, -0.0742, -0.2427,  ...,  0.2109, -0.4469, -0.1626],\n",
       "        [-1.0469, -0.0698, -0.4209,  ...,  0.6631,  0.4346,  0.1270]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[64:128,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "d_model = 512\n",
    "kv_heads = 4\n",
    "n_heads = 8\n",
    "for layer in t5_gqa.decoder.block:\n",
    "        # print(layer.layer[0].SelfAttention.q)\n",
    "        curr_self_attention_layer = layer.layer[0].SelfAttention\n",
    "        k_weight_data = curr_self_attention_layer.k.weight.data\n",
    "        k_weight_data = k_weight_data.view(kv_heads,d_model//n_heads,d_model)\n",
    "        k_weight_data = torch.repeat_interleave(k_weight_data,2,dim=1).view(-1,d_model)\n",
    "        \n",
    "        v_weight_data = curr_self_attention_layer.v.weight.data\n",
    "        v_weight_data = v_weight_data.view(kv_heads,d_model//n_heads,d_model)\n",
    "        v_weight_data = torch.repeat_interleave(v_weight_data,2,dim=1).view(-1,d_model)\n",
    "        \n",
    "        curr_self_attention_layer.k = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "        curr_self_attention_layer.v = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "        \n",
    "        curr_self_attention_layer.k.weight.data = k_weight_data\n",
    "        curr_self_attention_layer.v.weight.data = v_weight_data\n",
    "\n",
    "        curr_cross_attention_layer = layer.layer[1].EncDecAttention\n",
    "        k_weight_data = curr_cross_attention_layer.k.weight.data\n",
    "        k_weight_data = k_weight_data.view(kv_heads,d_model//n_heads,d_model)\n",
    "        k_weight_data = torch.repeat_interleave(k_weight_data,2,dim=1).view(-1,d_model)\n",
    "        \n",
    "        v_weight_data = curr_cross_attention_layer.v.weight.data\n",
    "        v_weight_data = v_weight_data.view(kv_heads,d_model//n_heads,d_model)\n",
    "        v_weight_data = torch.repeat_interleave(v_weight_data,2,dim=1).view(-1,d_model)\n",
    "        \n",
    "        curr_cross_attention_layer.k = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "        curr_cross_attention_layer.v = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "        \n",
    "        curr_cross_attention_layer.k.weight.data = k_weight_data\n",
    "        curr_cross_attention_layer.v.weight.data = v_weight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.modeling_t5.T5ForConditionalGeneration"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t5_gqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t5_gqa \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDistributedDataParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt5_gqa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_unused_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m t5_gqa\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py:625\u001b[0m, in \u001b[0;36mDistributedDataParallel.__init__\u001b[0;34m(self, module, device_ids, output_device, dim, broadcast_buffers, process_group, bucket_cap_mb, find_unused_parameters, check_reduction, gradient_as_bucket_view, static_graph)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device \u001b[38;5;241m=\u001b[39m _get_device_index(output_device, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_group \u001b[38;5;241m=\u001b[39m \u001b[43m_get_default_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_group \u001b[38;5;241m=\u001b[39m process_group\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:707\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03mGetting the default process group created by init_process_group\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_initialized():\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault process group has not been initialized, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease make sure to call init_process_group.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    710\u001b[0m     )\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GroupMember\u001b[38;5;241m.\u001b[39mWORLD\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "t5_gqa = torch.nn.parallel.DistributedDataParallel(t5_gqa, find_unused_parameters=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])\n",
      "Shape = torch.Size([256, 512])\n",
      "Reshaped a = tensor([[[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "        [[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "        [[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]],\n",
      "\n",
      "        [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]],\n",
      "\n",
      "        [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]]])\n",
      "Shape = torch.Size([64, 4, 512])\n",
      "Expanded a =  tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])\n",
      "Shape:  torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#               (d_model,kv_heads,d_model//n_heads)\n",
    "#(512,256) --> (512,4,64) --> repeat interleave along dimension one --> (512, 8, 64)\n",
    "\n",
    "d_model = 512 #512\n",
    "n_heads = 8 #8\n",
    "key_value_dim = d_model//n_heads #64\n",
    "kv_heads = 4 #4\n",
    "\n",
    "a = torch.ones((256,512))\n",
    "\n",
    "\n",
    "# a[0,:] = 0.1\n",
    "# a[1,:] = 0.2\n",
    "# a[2,:] = 0.3\n",
    "# a[3,:] = 0.4\n",
    "first_val = 0.1\n",
    "for i in range(0,a.shape[0],64):\n",
    "    a[i:i+64,:] = first_val\n",
    "    first_val+=0.1\n",
    "\n",
    "print(f\"a = {a}\")\n",
    "print(f\"Shape = {a.shape}\")\n",
    "a = a.view(key_value_dim,kv_heads,d_model)\n",
    "print(f\"Reshaped a = {a}\")\n",
    "print(f\"Shape = {a.shape}\")\n",
    "c = torch.repeat_interleave(a,2,dim=1).view(d_model,-1)\n",
    "\n",
    "print(\"Expanded a = \",c)\n",
    "print(\"Shape: \",c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],\n",
       "        [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],\n",
       "        [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],\n",
       "        ...,\n",
       "        [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],\n",
       "        [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],\n",
       "        [0.3000, 0.3000, 0.3000,  ..., 0.3000, 0.3000, 0.3000]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in c:\n",
    "#     print(i[0])\n",
    "#     # break\n",
    "c[128:257,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_head = b[:,0,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        ...,\n",
       "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        ...,\n",
       "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])\n",
      "Shape = torch.Size([256, 512])\n",
      "Reshaped a = tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])\n",
      "Shape = torch.Size([4, 64, 512])\n",
      "Expanded a =  tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]])\n",
      "Shape:  torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#               (d_model,kv_heads,d_model//n_heads)\n",
    "#(512,256) --> (512,4,64) --> repeat interleave along dimension one --> (512, 8, 64)\n",
    "\n",
    "d_model = 512 #512\n",
    "n_heads = 8 #8\n",
    "key_value_dim = d_model//n_heads #64\n",
    "kv_heads = 4 #4\n",
    "\n",
    "a = torch.ones((256,512))\n",
    "\n",
    "\n",
    "# a[0,:] = 0.1\n",
    "# a[1,:] = 0.2\n",
    "# a[2,:] = 0.3\n",
    "# a[3,:] = 0.4\n",
    "first_val = 0.1\n",
    "for i in range(0,a.shape[0],64):\n",
    "    a[i:i+64,:] = first_val\n",
    "    first_val+=0.1\n",
    "\n",
    "print(f\"a = {a}\")\n",
    "print(f\"Shape = {a.shape}\")\n",
    "b = a.view(kv_heads,key_value_dim,d_model)\n",
    "print(f\"Reshaped a = {a}\")\n",
    "print(f\"Shape = {b.shape}\")\n",
    "c = torch.repeat_interleave(b,2,dim=0).view(d_model,-1)\n",
    "\n",
    "print(\"Expanded a = \",c)\n",
    "print(\"Shape: \",c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        ...,\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_head = b[0,:,:] \n",
    "first_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n"
     ]
    }
   ],
   "source": [
    "for i in c[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        ...,\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
