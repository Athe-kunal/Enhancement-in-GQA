{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer,T5Config\n",
    "from transformers.models.t5.modeling_t5 import T5Attention, T5Config, T5Block\n",
    "from copy import deepcopy\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.models.t5.modeling_t5 import T5Attention, T5LayerSelfAttention, T5LayerCrossAttention\n",
    "\n",
    "t5: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_tf_attention_dict(module,kv_heads:int=4):\n",
    "    transfer_to_gqa: List[str] = [\"decoder\",\"EncDecAttention\"]\n",
    "    tf_attention_dict = defaultdict(list)\n",
    "    def convert_t5_to_gqa(module, kv_heads: int,similarity_flag:bool=False,inplace: bool = False,curr_name:str=''):\n",
    "        \"\"\"Get the list of attention modules based on the flag about encoder, decoder or cross-attention\n",
    "\n",
    "        Args:\n",
    "            module: Transformer module/unit\n",
    "            kv_heads (int): Number of key-value heads\n",
    "            similarity_flag (bool, optional): Similarity GQA flag. Defaults to False.\n",
    "            inplace (bool, optional): inplace replace the model with GQA. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        if isinstance(module, T5Attention) and similarity_flag:\n",
    "            print(curr_name)\n",
    "            tf_attention_dict[curr_name].append(module)\n",
    "\n",
    "        out = module if inplace else deepcopy(module)\n",
    "        for name, child in out.named_children():\n",
    "            if name in transfer_to_gqa:\n",
    "                curr_name = name\n",
    "                similarity_flag = True\n",
    "            out._modules[name] = convert_t5_to_gqa(child, kv_heads=kv_heads,similarity_flag=similarity_flag, inplace=True,curr_name=curr_name)\n",
    "        return out\n",
    "\n",
    "    convert_t5_to_gqa(module,kv_heads=kv_heads)\n",
    "    return tf_attention_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n",
      "decoder\n",
      "EncDecAttention\n"
     ]
    }
   ],
   "source": [
    "tf_attn_dict = get_tf_attention_dict(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['decoder', 'EncDecAttention'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_attn_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_attn_dict['EncDecAttention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Attention(\n",
       "  (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (relative_attention_bias): Embedding(32, 8)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_qkv = tf_attn_dict['decoder'][0]\n",
    "first_qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = first_qkv.q.weight.data.T\n",
    "k = first_qkv.k.weight.data.T\n",
    "v = first_qkv.v.weight.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([512, 512]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape,q.shape,k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "#define 8 weights one for each key head and 8 weights one for each value head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your original matrix is named 'input_matrix' with dimensions (512, 512)\n",
    "input_matrix = torch.rand((512, 512))\n",
    "\n",
    "# Define the weight scalars w1, w2, ..., w8\n",
    "w_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# Reshape the input matrix to (512, 8, 64) to represent the 8 heads\n",
    "input_matrix_reshaped = input_matrix.view(512, 8, 64)\n",
    "\n",
    "# Multiply each head with its corresponding weight scalar\n",
    "output_heads = torch.stack([input_matrix_reshaped[:, i, :] * w_values[i] for i in range(8)], dim=1)\n",
    "\n",
    "# Sum the weighted heads along the second dimension to combine them\n",
    "output_matrix = output_heads.sum(dim=1)\n",
    "\n",
    "# Verify the shape of the resulting matrix (512, 512)\n",
    "print(output_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 65])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones((512,512))\n",
    "print(w)\n",
    "w = w.view(512,8,64)\n",
    "#(8x1) and (512,8,64)\n",
    "mul_val = torch.tensor([[0.1],[0.2],[0.4],[0.3],[0.5],[0.6],[0.7],[0.8]])\n",
    "# print(mul_val.shape)\n",
    "# w_1 = torch.reshape(w,())\n",
    "final_val = torch.multiply(w,mul_val)\n",
    "fv = final_val.view(512,512)\n",
    "fv[:,:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        ...,\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.8000, 0.8000, 0.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "w = torch.ones((512, 512))\n",
    "print(w)\n",
    "\n",
    "w = w.view(512, 8, 64)\n",
    "# (8x1) and (512,8,64)\n",
    "mul_val = torch.tensor([[0.1], [0.2], [0.4], [0.3], [0.5], [0.6], [0.7], [0.8]])\n",
    "\n",
    "# Ensure mul_val has the same size as the second dimension of w\n",
    "mul_val = mul_val.view(1, 8, 1)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "final_val = torch.multiply(w, mul_val)\n",
    "\n",
    "# Reshape the result to the original shape (512, 512)\n",
    "fv = final_val.view(512, 512)\n",
    "\n",
    "print(fv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23397/3759601383.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  print(mul_val.T.shape)\n"
     ]
    }
   ],
   "source": [
    "print(mul_val.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_0_5 = torch.full((8, 1), 0.5)\n",
    "\n",
    "# Print the resulting tensor\n",
    "print(tensor_0_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn((8,1))\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,attn_module in tf_attn_dict['decoder']:\n",
    "    q = attn_module.q.weight.data.T\n",
    "    k = attn_module.k.weight.data.T\n",
    "    v = attn_module.v.weight.data.T\n",
    "\n",
    "    params = nn.ParameterDict({\n",
    "        f\"key_{idx}\": nn.Parameter(torch.full((num_heads,1),0.5)),\n",
    "        f\"value_{idx}\": nn.Parameter(torch.full((num_heads,1),0.5)),\n",
    "    })\n",
    "\n",
    "    k = k.view(512,num_heads,512//num_heads)\n",
    "    v = v.view(512,num_heads,512//num_heads)\n",
    "    k_mod = torch.multiply(k,params[f\"key_{idx}\"])\n",
    "    v_mod = torch.multiply(v,params[f\"value_{idx}\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b: batch_size\n",
    "# @n: seq_length\n",
    "# d: d_model\n",
    "# h:heads\n",
    "# k: same as d_model\n",
    "                #16,\n",
    "Q= tf .einsum(\"bnd,hdk->bhnk\" , X, P_q) \n",
    "K= tf .einsum(\"bmd,dk->bmk\" , M, P_k) \n",
    "V= tf .einsum(\"bmd,dv->bmv\" , M, P_v) \n",
    "logits = tf .einsum(\"bhnk,bmk->bhnm\", Q, K) \n",
    "weights= tf .softmax(logits +mask) \n",
    "O= tf .einsum(\"bhnm,bmv->bhnv\", weights , V)\n",
    "Y= tf .einsum(\"bhnv,hd->bnd\" , O, P_o) \n",
    "# return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello_there': 1, 'hello_jackass': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = {\"there\":1,\"jackass\":2}\n",
    "{\"hello_\"+k:v for k,v in c.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x\n",
    "torch.transpose(x, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHORT_SUM'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"SHORT_sum\".upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVE\n",
    "1. Take a GQA model, repeat interleave to expand it and then save it\n",
    "2. AFter that do again similarity based re-ordering and build the GQA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t5_SGQA import convert_t5_to_gqa\n",
    "from config import * \n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "t5: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\n",
    "        MODEL_NAME\n",
    "    )\n",
    "\n",
    "t5_gqa = convert_t5_to_gqa(t5,kv_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_gqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5.decoder.block.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "d_model = 512\n",
    "kv_heads = 4\n",
    "n_heads = 8\n",
    "for layer in t5_gqa.decoder.block:\n",
    "    # print(layer.layer[0].SelfAttention.q)\n",
    "    curr_self_attention_layer = layer.layer[0].SelfAttention\n",
    "    k_weight_data = curr_self_attention_layer.k.weight.data\n",
    "    k_weight_data = k_weight_data.view(d_model//n_heads,kv_heads,d_model)\n",
    "    k_weight_data = torch.repeat_interleave(k_weight_data,2,dim=1).view(-1,d_model)\n",
    "    \n",
    "    v_weight_data = curr_self_attention_layer.v.weight.data\n",
    "    v_weight_data = v_weight_data.view(d_model//n_heads,kv_heads,d_model)\n",
    "    v_weight_data = torch.repeat_interleave(v_weight_data,2,dim=1).view(-1,d_model)\n",
    "    \n",
    "    curr_self_attention_layer.k = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "    curr_self_attention_layer.v = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "    \n",
    "    curr_self_attention_layer.k.weight.data = k_weight_data\n",
    "    curr_self_attention_layer.v.weight.data = v_weight_data\n",
    "\n",
    "    curr_cross_attention_layer = layer.layer[1].EncDecAttention\n",
    "    k_weight_data = curr_cross_attention_layer.k.weight.data\n",
    "    k_weight_data = k_weight_data.view(d_model//n_heads,kv_heads,d_model)\n",
    "    k_weight_data = torch.repeat_interleave(k_weight_data,2,dim=1).view(-1,d_model)\n",
    "    \n",
    "    v_weight_data = curr_cross_attention_layer.v.weight.data\n",
    "    v_weight_data = torch.repeat_interleave(v_weight_data,2,dim=1).view(-1,d_model)\n",
    "    \n",
    "    curr_cross_attention_layer.k = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "    curr_cross_attention_layer.v = nn.Linear(in_features=512,out_features=512,bias=False)\n",
    "    \n",
    "    curr_cross_attention_layer.k.weight.data = k_weight_data\n",
    "    curr_cross_attention_layer.v.weight.data = v_weight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): CustomT5SelfAttention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_gqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Shape = torch.Size([4, 8])\n",
      "Expanded a =  tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
      "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
      "        [0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000],\n",
      "        [0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000]])\n",
      "Shape:  torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#               (d_model,kv_heads,d_model//n_heads)\n",
    "#(512,256) --> (512,4,64) --> repeat interleave along dimension one --> (512, 8, 64)\n",
    "\n",
    "d_model = 8 #512\n",
    "n_heads = 4 #8\n",
    "key_value_dim = d_model//n_heads #64\n",
    "kv_heads = 2 #4\n",
    "\n",
    "a = torch.ones((4,8))\n",
    "print(f\"a = {a}\")\n",
    "print(f\"Shape = {a.shape}\")\n",
    "\n",
    "a[0,:] = 0.1\n",
    "a[1,:] = 0.2\n",
    "a[2,:] = 0.3\n",
    "a[3,:] = 0.4\n",
    "a = a.view(key_value_dim,kv_heads,d_model)\n",
    "a = torch.repeat_interleave(a,2,dim=1).view(d_model,-1)\n",
    "\n",
    "print(\"Expanded a = \",a)\n",
    "print(\"Shape: \",a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.view(8,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
       "        [0.1000, 0.2000, 0.3000, 0.4000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0] = 0.1\n",
    "b[:,1] = 0.2\n",
    "b[:,2] = 0.3\n",
    "b[:,3] = 0.4\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
